\documentclass[10pt]{article}

\usepackage{mcclanahan}

\title{Simultaneous Productions: \\ A Fully General Grammar Specification}
\date{2021-04-18}
\author{Danny McClanahan}

\newcommand{\todocite}[1]{\footnote{cite: #1}}

\newcommand{\leftmost}[1]{\text{leftmost}(#1)}
\newcommand{\rightmost}[1]{\text{rightmost}(#1)}
\newcommand{\generalsubseq}{\overbar{I}}
\newcommand{\leftsubseq}{\generalsubseq}
\newcommand{\rightsubseq}{\generalsubseq'}

\newcommand{\leftleft}{\leftmost{\leftsubseq}}
\newcommand{\leftrignt}{\leftmost{\rightsubseq}}
\newcommand{\rightleft}{\rightmost{\leftsubseq}}
\newcommand{\rightright}{\rightmost{\rightsubseq}}

\newcommand{\lookingleft}{\text{Left}}
\newcommand{\lookingright}{\text{Right}}
\newcommand{\lookingat}{L_{\updownarrow}}
\newcommand{\lookdirection}{\{\lookingleft, \lookingright\}}
\newcommand{\lookdirectionset}{\{ \text{LookDirection} \}}

\newcommand{\subseqset}{\{\generalsubseq\}}
\newcommand{\subseqsetpair}{\subseqset \times \subseqset}

\newcommand{\opsuccess}{\text{Success}}
\newcommand{\opfailure}{\text{Failure}}
\newcommand{\ophasnoclue}{\text{IDK}}
\newcommand{\maybeopspace}{\{\opsuccess, \opfailure, \ophasnoclue\}}
\newcommand{\opresultset}{\{ \text{Result} \}}

\newcommand{\substringwith}[2]{\overbar{I}_{(#1,#2)}}
\newcommand{\canonicalleftend}{l_1}
\newcommand{\canonicalrightend}{l_2}
\newcommand{\canonicalsubstring}{\substringwith{\canonicalleftend}{\canonicalrightend}}
\newcommand{\bookmarkwith}[1]{\widehat{I}_{(#1)}}
\newcommand{\canonicalbookmarkindex}{l^+}
\newcommand{\canonicalbookmark}{\bookmarkwith{\canonicalbookmarkindex}}

\begin{document}
\maketitle

\section{Motivation for a New Grammar Specification}
\label{sec:motivation}

This paper is the first of several on a parsing method we will refer to as ``Simultaneous Productions'' (or ``S.P.'' for short). This name was chosen to emphasize two goals of this method:
\begin{enumerate}
  \item An S.P. \textit{grammar} is composed of a set of \textit{productions}, very similar to most existing concepts of formal grammars \todocite{chomsky formal grammars}. However, unlike many common parsing algorithms \todocite{common parsing algorithms -- frequency and power? maybe cite history of parsing page?}, an S.P. grammar can represent a recursively enumerable language \todocite{what is RecEnum?}.
  \item When parsing a string, these productions can be independently evaluated over separate parts of the input string, and adjacent successful matches can then be merged to form a successful parse. Unlike many common parsing algorithms, this feature avoids any intrinsic serial dependencies that require parsing the beginning of the string first, hence allowing for \textit{parallelism} during the parsing process.
\end{enumerate}

\subsection{Goals of This Paper}
\label{sec:goals}
We have noted that the above two features are not shared by many commonly-used parsing algorithms \todocite{the history of parsing webpage}. In this paper, we will describe the S.P. \textit{grammar-grammar}, i.e. the specification which defines any S.P. grammar. We hope to show that:
\begin{itemize}
  \item The S.P. grammar-grammar is equivalent to Chomsky's canonical specification of a formal language \todocite{chomsky formal grammars again}.
  \item An S.P. grammar can \textit{easily and naturally represent} many of the common use cases for parsers. This is a subjective measure of the ease to develop an appropriate grammar for the \textit{grammar-writer}, and can likely be improved upon. The \textit{grammar-writer} is perceived to a be human being attempting to create a grammar to parse some ``real-world'' input.
  \item Furthermore, representing a grammar with S.P. \textbf{does not introduce any additional complexity} for the grammar-writer over other common grammar specifications, such as those used for regular expressions (DFAs) \todocite{what are DFAs/regex}, regex with backrefs (recursively enumerable) \todocite{backrefs are RecEnum}, as well as EBNF syntax commonly used for CFGs \todocite{use of EBNF for CFGs}.
\end{itemize}

\subsection{Followup Work}
\label{sec:followup-work}
Further paper(s) will describe an efficient parsing algorithm to evaluate an S.P. grammar over a specific input string. The intention of this separation is to allow the S.P. grammar-grammar to be reviewed and criticized separately from the evaluation method. This is done because the author believes that the S.P. grammar-grammar has merit in itself, as a ``lingua franca'' for \textit{executable formal grammars}, that is, grammars which can be efficiently parsed by computer.

\subsection{Notation}
\label{sec:notation}
\begin{itemize}
  \item Named concepts in this paper will be represented in \textit{italics} when first defined.
  \item Capital letters generally refer to sets, while lowercase letters generally refer to elements of some set. This may not be true in all cases.
  \item As an abbreviation, $[n] = [1, n] \forall n \in \N$, and $\pipe$ should be translated as ``for some''.
\end{itemize}

\section{Definition}
\label{sec:definition}
We first define the \textit{S.P. grammar-grammar}, as a kind of meta-grammar which specifies all concrete S.P. grammars. We use the term grammar-grammar to emphasize the regular structure of an S.P. grammar. We believe this formulation is relatively simple to analyze, and in subsequent work we will demonstrate that it admits a relatively performant \textit{parsing algorithm}, or \textit{evaluation method}. It is possible this representation can be further improved.

\subsection{S.P. Grammar-Grammar}
\label{sec:grammar-grammar}
\begin{equation}
  \label{eq:sp}
  SP = (\Sigma, \scr{P}).
\end{equation}
An \textit{S.P. grammar} $SP$ is a 2-tuple with an arbitrary finite set $\Sigma$ and a finite set of productions $\scr{P}$ defined in \expliciteqnref{eq:p}. We refer to $\Sigma$ as the \textit{alphabet}.

\begin{equation}
  \label{eq:p}
  p = \scr{C}_p \forall p \in \scr{P}.
\end{equation}
Each \textit{production} $p$ is a finite set of cases $\scr{C}_p$, defined in \expliciteqnref{eq:cp}.

\begin{equation}
  \label{eq:cp}
  c_p = \{e_j\}_{j=1}^m \forall c_p \in \scr{C}_p.
\end{equation}
Each \textit{case} $c_p$ is a finite sequence of case elements $\{e_j\}_{j=1}^m$, where $m$ is the number of elements in the sequence $c_p$, with $e_j$ defined in \expliciteqnref{eq:ej}.

\begin{equation}
  \label{eq:ej}
  e_j = \begin{alignedcases}{c}
    t \in \Sigma, \\
    p \in \scr{P}.
  \end{alignedcases} \forall j \in [m].
\end{equation}
Each \textit{case element} $e_j$ is either a \textit{terminal} $t \in \Sigma$ or \textit{nonterminal} $p \in \scr{P}$.

\section{Parsing}
\label{sec:parsing}
The act of \textit{parsing} given a grammar $SP$ requires introducing a few more concepts. The definition of parsing is completely separated from the definition of a grammar \explicitsecref{sec:definition}.

In short, each production $p \in \scr{P}$ can be \textit{matched} against some input string $I$ when \textbf{any} case $c_p \in \scr{C}_p$ matches $I$. $c_p$ matches $I$ iff \textbf{all} terminals and nonterminals are matched against consecutive non-overlapping subsequences of the input string $I$.

\subsection{Input Specification}
\label{sec:input-specification}
\begin{equation}
  \label{eq:input-string-tokens}
  I = \{t_i\}_{i=1}^n \pipe t_i \in \Sigma \forall i \in [n].
\end{equation}
An \textit{input string} $I$ is a finite sequence of \textit{tokens} $\{t_i\}_{i=1}^n$ from the alphabet $\Sigma$, where $\abs{I} = n$ is the number of elements in the sequence $I$.

\subsection{Partitioning the Input}
\label{sec:partitioning-the-input}
We would like to be able to reason independently about how different subsequences $\generalsubseq$ of the input $I$ may match a certain production $p \in \scr{P}$. We eventually make use of this reasoning in \explicitsecref{sec:matching-a-prod}, where we describe how to check whether an arbitrary production $p$ matches an arbitrary $\generalsubseq$. In later work we hope to show that this enables highly scalable performance gains through caching and parallelism techniques.

\subsubsection{Substrings, Bookmarks, and Subsequences}
\label{sec:subsequences}
We define two methods to represent a \textit{subsequence} $\generalsubseq$ of the input string $I$: \textit{substrings} $\canonicalsubstring$ and \textit{bookmarks} $\canonicalbookmark$.

\begin{align}
  \label{eq:subsequences}
  \generalsubseq_{\canonicalleftend,l_2} &= \{t_i\}_{i=\canonicalleftend}^{l_2} &&= \text{substring}(I, \canonicalleftend, l_2) &&&\pipe &&&\canonicalleftend \le l_2 \le n \in \N. \\
  \canonicalbookmark &= \{\} &&= \text{bookmark}(I, \canonicalbookmarkindex) &&&\pipe &&&\canonicalbookmarkindex \in [n + 1]. \\
  \subseqset &= \{\generalsubseq_{\canonicalleftend,l_2}\} \disjcup \{\canonicalbookmark\} &&= \text{subsequences}(I).
\end{align}
The \textit{substring} $\generalsubseq_{\canonicalleftend,l_2}$ is the subsequence of $I$ from indices $\canonicalleftend$ to $l_2$, inclusive. The \textit{bookmark} $\canonicalbookmark$ is an empty sequence (technically an empty subsequence of $I$) which is inserted \textbf{before} the index $\canonicalbookmarkindex$. In the case that $\canonicalbookmarkindex = n + 1$, the bookmark $\canonicalbookmark$ is considered to be at the \textbf{end} of the input string $I$.

We use the notation $\subseqset$ to denote the disjoint union of these two types of \textit{subsequences} of $I$. Bookmarks are essentially only needed to represent productions which match the empty string (which are perfectly legal): see the matching process in \explicitsecref{sec:matching-a-prod}.

% \subsubsection{Sorting Subsequences}
% \label{sec:sorting-subsequences}
% We would like to be able to compare subsequences from separate, possibly-overlapping parts of the string, in order to produce a data structure that looks like a ``parse tree'', but which can also represent non-local dependencies, such as those found in context-sensitive and recursively enumerable languages \todocite{cite or prove for context-sensitivity requiring non-local deps!}.

% We first establish the ``leftmost'' and ``rightmost'' functions, and introduce the concept of ``adjacency'' for subsequences. We then produce an ``adjacency mapping'' construct which splits up the input $I$  \explicitsecref{sec:adjacency-mapping}.

% \begin{align}
%   \label{eq:leftmost-rightmost-span}
%   \begin{array}{rcl}
%     \begin{alignedcases}{lclcl}
%       \leftmost{\canonicalbookmark} &=& \canonicalbookmarkindex &\in& [n + 1], \\
%       \leftmost{\canonicalsubstring} &=& \canonicalleftend &\in& [n].
%     \end{alignedcases} &=& \leftmost{\generalsubseq} \forall \generalsubseq \in \subseqset. \\
%     \leftmost{\generalsubseq} &:& \subseqset \rightarrow [n + 1].
%   \end{array} \\
%   \begin{array}{rcl}
%     \begin{alignedcases}{lclcl}
%       \rightmost{\canonicalbookmark} &=& \canonicalbookmarkindex &\in& [n + 1], \\
%       \rightmost{\canonicalsubstring} &=& \canonicalrightend &\in& [n].
%     \end{alignedcases} &=& \rightmost{\generalsubseq} \forall \generalsubseq \in \subseqset. \\
%     \rightmost{\generalsubseq} &:& \subseqset \rightarrow [n + 1].
%   \end{array}
% \end{align}
% \textbf{TODO: ???}

% \begin{align}
%   \label{eq:f-minus}
%   \lookdirectionset &= \lookdirection. \\
%   \opresultset &= \maybeopspace. \\
%   F_-^+ &: \p{\subseqsetpair \times \lookdirection} \rightarrow \maybeopspace. \\
%   F_-(\leftsubseq, \rightsubseq) &= F_-^+(\leftsubseq, \rightsubseq, \lookingleft). \\
%   F^+(\leftsubseq, \rightsubseq) &= F_-^+(\leftsubseq, \rightsubseq, \lookingright). \\
%   F_-(\leftsubseq, \rightsubseq) &= \begin{alignedcases}{lcr}
%     \leftleft = \leftrignt &\Rightarrow& \opfailure, \\
%     \leftleft < \leftrignt &\Rightarrow& \opsuccess, \\
%     F_-(\rightsubseq, \leftsubseq) = \opsuccess &\Rightarrow& \opfailure, \\
%     \otherwise &\Rightarrow& \ophasnoclue.
%   \end{alignedcases} \\
%   F^+(\leftsubseq, \rightsubseq) &= \begin{alignedcases}{lcr}
%     \rightleft = \rightright &\Rightarrow& \opfailure, \\
%     \rightleft < \rightright &\Rightarrow& \opsuccess, \\
%     F^+(\rightsubseq, \leftsubseq) = \opsuccess &\Rightarrow& \opfailure, \\
%     \otherwise &\Rightarrow& \ophasnoclue.
%   \end{alignedcases}
% \end{align}
% The functions $F_-$ and $F^+$ provide ``less than'' and ``greater than'' operators which can compare any two subsequences of $I$, but may return an $\ophasnoclue$ result.

% \subsection{Adjacency}
% \label{sec:adjacency}
% We now attempt to strengthen our concept of ordering to represent \textit{adjacent} subsequences $\generalsubseq$ of $I$. We use this later in our definition of an adjacency mapping $\generalsubseq^*_k$ which ``spans'' the entire input $I$ \explicitsecref{sec:adjacency-mapping}.

% \subsubsection{Adjacent Subsequences}
% \label{sec:adjacent-subsequences}
% \begin{equation}
%   \label{eq:adjacent-subsequences}
%   \begin{array}{rl}
%     \subseqset \times \subseqset \rightarrow \ternarylogicspace &: \text{adjacent}. \\
%     \begin{alignedcases}{lcrcr}
%       \generalsubseq = \canonicalbookmark, \generalsubseq' = \widehat{I}_{{\canonicalbookmarkindex}'} &\Rightarrow& \canonicalbookmarkindex = {\canonicalbookmarkindex}' &\Leftrightarrow& \true, \\
%       \generalsubseq = \canonicalbookmark, \generalsubseq' = \generalsubseq_{\canonicalleftend',l_2'} &\Rightarrow& \canonicalbookmarkindex = \canonicalleftend' &\Leftrightarrow& \true, \\
%       \generalsubseq = \generalsubseq_{\canonicalleftend,l_2}, \generalsubseq' = \widehat{I}_{{\canonicalbookmarkindex}'} &\Rightarrow& l_2 = {\canonicalbookmarkindex}' + 1 &\Leftrightarrow& \true, \\
%       \generalsubseq = \generalsubseq_{\canonicalleftend,l_2}, \generalsubseq' = \generalsubseq_{\canonicalleftend',l_2'} &\Rightarrow& \canonicalleftend' = l_2 + 1 &\Leftrightarrow& \true, \\
%       \otherwise &\Rightarrow& && \undefval.
%     \end{alignedcases} &= \text{adjacent}(\generalsubseq, \generalsubseq').
%   \end{array}
% \end{equation}
% Two subsequences $\generalsubseq$ and $\generalsubseq'$ of $I$ are \textit{adjacent} when $\text{adjacent}(\generalsubseq, \overbar{I'}) = \true$. A bookmark is adjacent to another bookmark when they occupy the same position within $I$. A bookmark is adjacent to a substring when it is immediately before or immediately after the substring. Two substrings are adjacent when the end of one substring is immediately before the beginning of the other.

% \subsubsection{Adjacency Mapping}
% \label{sec:adjacency-mapping}
% \begin{align}
%   \label{eq:adjacency-mapping}
%   \{\generalsubseq_q\}_{q=1}^k &= \generalsubseq^*_k. \\
%   \begin{alignedcases}{rl}
%     \text{left boundary condition: } \generalsubseq_1 &= \begin{alignedcases}{c}
%       \widehat{I}_{(\canonicalbookmarkindex = 1)}, \text{ or} \\
%       \generalsubseq_{(\canonicalleftend=1),(l_2 \in [n])}.
%     \end{alignedcases},\text{ and} \\
%     \text{right boundary condition: } \generalsubseq_k &= \begin{alignedcases}{c}
%       \widehat{I}_{(\canonicalbookmarkindex = n+1)}, \text{ or} \\
%       \generalsubseq_{(\canonicalleftend \in [n]),(l_2=n)}.
%     \end{alignedcases},\text{ and} \\
%     \text{contiguous: } \text{adjacent}(\generalsubseq_q, \generalsubseq_{q + 1}) &= \true \forall q \in [k - 1].
%   \end{alignedcases} &\Leftrightarrow \generalsubseq^*_k \text{ spans } I.
% \end{align}
% An \textit{adjacency mapping} $\generalsubseq^*_k$ is a \textit{contiguous} or \textit{consecutively adjacent} sequence of length $k$ of subsequences $\{\generalsubseq_q\}_{q=1}^k$ of the input string $I$, in which the first element $\generalsubseq_1$ is adjacent to, or contains, the first element $t_1$ of $I$, and the final element $\generalsubseq_k$ is adjacent to, or contains, the last element $t_n$ of $I$. A bookmark for $\generalsubseq_1$ or $\generalsubseq_k$ would be adjacent to $t_1$ or $t_n$, while a substring would contain $t_1$ or $t_n$. We say that $\generalsubseq^*_k$ \textit{spans} the tokens of $I$.

\subsection{Matching a Production}
\label{sec:matching-a-prod}
We construct the predicate to answer the matching question for a production $\text{matches}_{(\scr{P})}$ recursively, by defining the ``matches'' function over multiple separate domains:

\begin{equation}
  \label{eq:matches-prod}
  \begin{array}{rl}
    \text{matches}_{(\scr{P})} &: \{SP\} \times \scr{P} \times \{I\} \rightarrow \binaryspace. \\
    \text{matches}_{(\scr{P})}(SP, p, I) &= \{ \exists p \in \scr{P}, c_p \in \scr{C}_p \pipe \text{matches}_{(\scr{C}_p)}(c_p, I) \Leftrightarrow \true \}.
  \end{array}
\end{equation}
A production $p \in \scr{P}$ \textit{matches} an input string $I$ when any of its cases $c_p \in \scr{C}_p$ match $I$ as defined in \expliciteqnref{eq:matches-case}.

\begin{equation}
  \label{eq:matches-case}
  \begin{array}{rl}
    \text{matches}_{(\scr{C}_p)} &: \scr{C}_p \times \{I\} \rightarrow \binaryspace. \\
    \text{matches}_{(\scr{C}_p)}(c_p, I) &= \{ \exists \generalsubseq^*_m \pipe \text{matches}_{(e_j)}(e_j, \generalsubseq_j) \forall j \in [m] \Leftrightarrow \true \}.
  \end{array}
\end{equation}
A case $c_p \in \scr{C}_p$ \textit{matches} an input string $I$ when there exists an adjacency mapping $\generalsubseq^*_m$ of length $m = \abs{c_p}$ which maps each case element $e_j$ to a subsequence $\generalsubseq_j$ such that every case element matches its assigned subsequence from the adjacency mapping as defined in \expliciteqnref{eq:matches-element}.

\begin{equation}
  \label{eq:matches-element}
  \begin{array}{rl}
    [m] \times \subseqset \rightarrow \binaryspace &: \text{matches}_{(e_j)}. \\
    \begin{alignedcases}{lcrcl}
      e_j = t \in \Sigma &\Rightarrow& \generalsubseq = \generalsubseq_{\canonicalleftend,l_2}, \canonicalleftend = l_2, I_{\canonicalleftend} = t &\Leftrightarrow& \true, \\
      e_j = p' \in \scr{P} &\Rightarrow& \text{matches}_{(\scr{P})}(SP, p', \generalsubseq) &\Leftrightarrow& \true.
    \end{alignedcases} &= \text{matches}_{(e_j)}(j, \generalsubseq).
  \end{array}
\end{equation}
A case element $e_j$ matches an input subsequence $\generalsubseq$ when $e_j$ is a token $t \in \Sigma$, in which case $\generalsubseq$ is a length-1 substring of $I$ containing the single token $t$, or when $e_j$ is a production $p'$, in which case the subsequence $\generalsubseq$ must match the production $p'$ as defined in \expliciteqnref{eq:matches-prod}.

\subsection{Grammar Specialization}
\label{sec:grammar-specialization}
\begin{equation}
  \label{eq:p-top}
  p^* \in \scr{P}.
\end{equation}
As described in \explicitsecref{sec:matching-a-prod}, an S.P. grammar $SP$ alone is not sufficient information to unambiguously parse a string -- a single production must also be specified. Therefore to get an \textit{executable grammar}, we select a single ``top'' production $p^* \in \scr{P}$, corresponding to the \textit{start symbol} found in Chomsky grammars \explicitsecref{sec:chomsky-equivalence}.

\begin{equation}
  \label{eq:specialized}
  SP^* = (\Sigma, \scr{P}, p^*).
\end{equation}
The tuple $SP^*$ formed from the selection of $p^*$ is referred to as a \textit{specialized grammar}. For this reason, we may also refer to a grammar $SP$ (without having chosen any $p^*$ yet) as an \textit{unspecialized grammar}.

\subsection{Summary of Adjacency}
\label{sec:summary-of-adjacency}
At this stage, we note a few important points:
\begin{enumerate}
  \item An adjacency mapping $\generalsubseq^*_k$ essentially represents a parse tree \textbf{TODO: HOW??? CROSS-SERIAL DEPS???}
  \item A production $p$ may match a finite or countably infinite number of subsequences $\generalsubseq$ of $I$, not just one. So, if we say $p$ matches $\generalsubseq$ for some case $c_p$, it may still match other subsequences $\generalsubseq'$, either for the same case $c_p$, or other cases $c'_p \in \scr{C}_p$.
  \item We have not yet described a method to \textbf{actually construct an adjacency mapping $\generalsubseq^*$ for a given specialized grammar and input}. That is out of scope for this paper.
\end{enumerate}

\section{Proof of Turing-Equivalence}
\label{sec:proof-of-turing-equivalence}


\section{Chomsky Equivalence}
\label{sec:chomsky-equivalence}
We have described an S.P. grammar $SP = (\Sigma, \scr{P})$ \explicitsecref{sec:grammar-grammar}, and we have \textit{specialized} the grammar into $SP^* = (\Sigma, \scr{P}, p^*)$ by selecting a production $p \in \scr{P}$ \explicitsecref{sec:grammar-specialization}. We have described the conditions under which $p^*$ is said to successfully match an input string $I$ consisting of tokens from $\Sigma$ \explicitsecref{sec:matching-a-prod}.

We attempt to directly reduce the canonical specification of a formal grammar (often attributed to Noam Chomsky) into specialized or executable form $SP^*$ \todocite{chomsky grammars}.

\subsection{Chomsky Construct}
\label{sec:chomsky-construct}
The definition of a ``formal grammar'' we copy from Noam Chomsky as follows \todocite{chomsky!!!}:

\subsubsection{Formal Grammar Definition}
\label{sec:formal-grammar-definition}
\begin{align}
  \label{eq:chomsky-production}
  \Sigma &\text{: terminal symbols.} \\
  N &\text{: nonterminal symbols.} \\
  S &\text{: start symbol.} \in N \\
  P &\text{: productions.} \\
  P &= \{\p{\Sigma\, \cup \, N}^* N \p{\Sigma\, \cup \, N}^* \rightarrow \p{\Sigma\, \cup \, N}^* \}. \\
  G &= (N, \Sigma, P, S).
\end{align}

\subsubsection{Parsing a Formal Grammar}
\label{sec:parsing-a-formal-grammar}
asdf

\subsection{Equivalence Proof}
\label{sec:equivalence-proof}
We will perform a Cook-Levin-style reduction from a Chomsky grammar $G = (N, \Sigma, P, S)$ \explicitsecref{sec:chomsky-construct} into a specialized S.P grammar $SP^* = (\Sigma, \scr{P}, p^*)$ \explicitsecref{sec:grammar-specialization} \todocite{cook-levin!}.

\subsubsection{Construction of $\Sigma_{SP^*}$}
\label{sec:construction-of-sigma}
\begin{equation}\label{eq:alphabet}
  \Sigma_{SP^*} = \Sigma_G.
\end{equation}
The alphabet $\Sigma$ is exactly the same in both S.P. and the Chomsky formulation.

\subsubsection{Construction of $\scr{P}$}
\label{sec:construction-of-p}
\begin{equation}
  \label{eq:productions-reduction}
  asdf
\end{equation}

\section{Relevant Prior Art / Notes}
\subsection{Overview}
\label{sec:overview}

asdf

\end{document}
